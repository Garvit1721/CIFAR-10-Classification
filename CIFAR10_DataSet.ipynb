{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f610da2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\VICTUS\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f19285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1630fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cfad37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train is (50000, 32, 32, 3)\n",
      "Shape of x_test is (10000, 32, 32, 3)\n",
      "Shape of y_train is (50000, 1)\n",
      "Shape of y_test is (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x_train is {}'.format(x_train.shape))\n",
    "print('Shape of x_test is {}'.format(x_test.shape)) \n",
    "print('Shape of y_train is {}'.format(y_train.shape))\n",
    "print('Shape of y_test is {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad9bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "x_train=x_train/255\n",
    "x_test=x_test/255\n",
    "y_train_cat=to_categorical(y_train,10)\n",
    "y_test_cat=to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1fa19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout,Input, AveragePooling2D, Activation,Conv2D, MaxPooling2D, BatchNormalization,Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98819a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\VICTUS\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\VICTUS\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\VICTUS\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\VICTUS\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\VICTUS\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "781/781 [==============================] - 57s 69ms/step - loss: 1.9493 - accuracy: 0.3406 - val_loss: 1.7730 - val_accuracy: 0.4165\n",
      "Epoch 2/200\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 1.4678 - accuracy: 0.4665 - val_loss: 1.2492 - val_accuracy: 0.5406\n",
      "Epoch 3/200\n",
      "781/781 [==============================] - 52s 67ms/step - loss: 1.2991 - accuracy: 0.5351 - val_loss: 1.1382 - val_accuracy: 0.6014\n",
      "Epoch 4/200\n",
      "781/781 [==============================] - 65s 83ms/step - loss: 1.1834 - accuracy: 0.5770 - val_loss: 1.1292 - val_accuracy: 0.6108\n",
      "Epoch 5/200\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 1.0930 - accuracy: 0.6156 - val_loss: 0.9614 - val_accuracy: 0.6643\n",
      "Epoch 6/200\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 1.0281 - accuracy: 0.6429 - val_loss: 1.2030 - val_accuracy: 0.6150\n",
      "Epoch 7/200\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.9825 - accuracy: 0.6606 - val_loss: 0.8642 - val_accuracy: 0.7043\n",
      "Epoch 8/200\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 0.9331 - accuracy: 0.6761 - val_loss: 0.8180 - val_accuracy: 0.7126\n",
      "Epoch 9/200\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.9005 - accuracy: 0.6899 - val_loss: 0.7274 - val_accuracy: 0.7479\n",
      "Epoch 10/200\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 0.8848 - accuracy: 0.6937 - val_loss: 0.7762 - val_accuracy: 0.7364\n",
      "Epoch 11/200\n",
      "781/781 [==============================] - 59s 76ms/step - loss: 0.8690 - accuracy: 0.7032 - val_loss: 0.8684 - val_accuracy: 0.7165\n",
      "Epoch 12/200\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 0.8370 - accuracy: 0.7111 - val_loss: 0.8527 - val_accuracy: 0.7200\n",
      "Epoch 13/200\n",
      "781/781 [==============================] - 59s 75ms/step - loss: 0.8166 - accuracy: 0.7198 - val_loss: 0.6846 - val_accuracy: 0.7716\n",
      "Epoch 14/200\n",
      "781/781 [==============================] - 66s 84ms/step - loss: 0.7919 - accuracy: 0.7281 - val_loss: 0.6917 - val_accuracy: 0.7640\n",
      "Epoch 15/200\n",
      "781/781 [==============================] - 61s 78ms/step - loss: 0.7915 - accuracy: 0.7285 - val_loss: 0.7167 - val_accuracy: 0.7573\n",
      "Epoch 16/200\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 0.7646 - accuracy: 0.7400 - val_loss: 0.6278 - val_accuracy: 0.7876\n",
      "Epoch 17/200\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.7447 - accuracy: 0.7451 - val_loss: 0.6649 - val_accuracy: 0.7786\n",
      "Epoch 18/200\n",
      "781/781 [==============================] - 62s 80ms/step - loss: 0.7487 - accuracy: 0.7464 - val_loss: 0.6389 - val_accuracy: 0.7869\n",
      "Epoch 19/200\n",
      "781/781 [==============================] - 61s 79ms/step - loss: 0.7341 - accuracy: 0.7521 - val_loss: 0.6200 - val_accuracy: 0.7908\n",
      "Epoch 20/200\n",
      "781/781 [==============================] - 58s 75ms/step - loss: 0.7133 - accuracy: 0.7592 - val_loss: 0.6290 - val_accuracy: 0.7895\n",
      "Epoch 21/200\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.7077 - accuracy: 0.7579 - val_loss: 0.6398 - val_accuracy: 0.7905\n",
      "Epoch 22/200\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 0.7017 - accuracy: 0.7612 - val_loss: 0.5779 - val_accuracy: 0.8037\n",
      "Epoch 23/200\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.6867 - accuracy: 0.7647 - val_loss: 0.5474 - val_accuracy: 0.8169\n",
      "Epoch 24/200\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.6760 - accuracy: 0.7694 - val_loss: 0.6327 - val_accuracy: 0.7959\n",
      "Epoch 25/200\n",
      "781/781 [==============================] - 61s 78ms/step - loss: 0.6789 - accuracy: 0.7713 - val_loss: 0.5331 - val_accuracy: 0.8205\n",
      "Epoch 26/200\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.6680 - accuracy: 0.7720 - val_loss: 0.5685 - val_accuracy: 0.8056\n",
      "Epoch 27/200\n",
      "781/781 [==============================] - 752s 964ms/step - loss: 0.6612 - accuracy: 0.7734 - val_loss: 0.6391 - val_accuracy: 0.7858\n",
      "Epoch 28/200\n",
      "781/781 [==============================] - 71s 91ms/step - loss: 0.6404 - accuracy: 0.7788 - val_loss: 0.5277 - val_accuracy: 0.8219\n",
      "Epoch 29/200\n",
      "781/781 [==============================] - 71s 91ms/step - loss: 0.6539 - accuracy: 0.7799 - val_loss: 0.6205 - val_accuracy: 0.7971\n",
      "Epoch 30/200\n",
      "781/781 [==============================] - 66s 85ms/step - loss: 0.6445 - accuracy: 0.7820 - val_loss: 0.5153 - val_accuracy: 0.8252\n",
      "Epoch 31/200\n",
      "781/781 [==============================] - 77s 98ms/step - loss: 0.6326 - accuracy: 0.7853 - val_loss: 0.5054 - val_accuracy: 0.8257\n",
      "Epoch 32/200\n",
      "781/781 [==============================] - 76s 97ms/step - loss: 0.6256 - accuracy: 0.7883 - val_loss: 0.6032 - val_accuracy: 0.7973\n",
      "Epoch 33/200\n",
      "781/781 [==============================] - 76s 97ms/step - loss: 0.6247 - accuracy: 0.7876 - val_loss: 0.5632 - val_accuracy: 0.8096\n",
      "Epoch 34/200\n",
      "781/781 [==============================] - 74s 95ms/step - loss: 0.6246 - accuracy: 0.7879 - val_loss: 0.5126 - val_accuracy: 0.8322\n",
      "Epoch 35/200\n",
      "781/781 [==============================] - 76s 97ms/step - loss: 0.6175 - accuracy: 0.7913 - val_loss: 0.5105 - val_accuracy: 0.8300\n",
      "Epoch 36/200\n",
      "781/781 [==============================] - 77s 98ms/step - loss: 0.6075 - accuracy: 0.7936 - val_loss: 0.5764 - val_accuracy: 0.8098\n",
      "Epoch 37/200\n",
      "781/781 [==============================] - 81s 104ms/step - loss: 0.6132 - accuracy: 0.7930 - val_loss: 0.4814 - val_accuracy: 0.8373\n",
      "Epoch 38/200\n",
      "781/781 [==============================] - 74s 95ms/step - loss: 0.6041 - accuracy: 0.7947 - val_loss: 0.5111 - val_accuracy: 0.8287\n",
      "Epoch 39/200\n",
      "781/781 [==============================] - 81s 104ms/step - loss: 0.6083 - accuracy: 0.7929 - val_loss: 0.6051 - val_accuracy: 0.8055\n",
      "Epoch 40/200\n",
      "781/781 [==============================] - 71s 91ms/step - loss: 0.5887 - accuracy: 0.7993 - val_loss: 0.5543 - val_accuracy: 0.8154\n",
      "Epoch 41/200\n",
      "781/781 [==============================] - 70s 90ms/step - loss: 0.5903 - accuracy: 0.8001 - val_loss: 0.4859 - val_accuracy: 0.8360\n",
      "Epoch 42/200\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.5880 - accuracy: 0.8020 - val_loss: 0.4989 - val_accuracy: 0.8344\n",
      "Epoch 43/200\n",
      "781/781 [==============================] - 120s 154ms/step - loss: 0.5902 - accuracy: 0.8008 - val_loss: 0.5029 - val_accuracy: 0.8327\n",
      "Epoch 44/200\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.5891 - accuracy: 0.7997 - val_loss: 0.5616 - val_accuracy: 0.8196\n",
      "Epoch 45/200\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.5804 - accuracy: 0.8040 - val_loss: 0.4818 - val_accuracy: 0.8436\n",
      "Epoch 46/200\n",
      "781/781 [==============================] - 48s 61ms/step - loss: 0.5698 - accuracy: 0.8058 - val_loss: 0.5302 - val_accuracy: 0.8234\n",
      "Epoch 47/200\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.5659 - accuracy: 0.8072 - val_loss: 0.5247 - val_accuracy: 0.8236\n",
      "Epoch 48/200\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5718 - accuracy: 0.8051 - val_loss: 0.4926 - val_accuracy: 0.8379\n",
      "Epoch 49/200\n",
      "781/781 [==============================] - 46s 59ms/step - loss: 0.5588 - accuracy: 0.8097 - val_loss: 0.5956 - val_accuracy: 0.8059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5592 - accuracy: 0.8098 - val_loss: 0.4441 - val_accuracy: 0.8485\n",
      "Epoch 51/200\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5610 - accuracy: 0.8119 - val_loss: 0.4888 - val_accuracy: 0.8374\n",
      "Epoch 52/200\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5489 - accuracy: 0.8171 - val_loss: 0.4983 - val_accuracy: 0.8341\n",
      "Epoch 53/200\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5629 - accuracy: 0.8115 - val_loss: 0.4546 - val_accuracy: 0.8483\n",
      "Epoch 54/200\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5441 - accuracy: 0.8149 - val_loss: 0.4360 - val_accuracy: 0.8533\n",
      "Epoch 55/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5493 - accuracy: 0.8142 - val_loss: 0.4428 - val_accuracy: 0.8520\n",
      "Epoch 56/200\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5511 - accuracy: 0.8131 - val_loss: 0.4548 - val_accuracy: 0.8435\n",
      "Epoch 57/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5398 - accuracy: 0.8197 - val_loss: 0.4245 - val_accuracy: 0.8566\n",
      "Epoch 58/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5486 - accuracy: 0.8172 - val_loss: 0.4957 - val_accuracy: 0.8366\n",
      "Epoch 59/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5488 - accuracy: 0.8148 - val_loss: 0.4127 - val_accuracy: 0.8605\n",
      "Epoch 60/200\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5399 - accuracy: 0.8200 - val_loss: 0.4596 - val_accuracy: 0.8432\n",
      "Epoch 61/200\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.5362 - accuracy: 0.8201 - val_loss: 0.4857 - val_accuracy: 0.8374\n",
      "Epoch 62/200\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.5245 - accuracy: 0.8211 - val_loss: 0.4618 - val_accuracy: 0.8503\n",
      "Epoch 63/200\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.5322 - accuracy: 0.8185 - val_loss: 0.4624 - val_accuracy: 0.8467\n",
      "Epoch 64/200\n",
      "781/781 [==============================] - 48s 61ms/step - loss: 0.5276 - accuracy: 0.8220 - val_loss: 0.4149 - val_accuracy: 0.8612\n",
      "Epoch 65/200\n",
      "781/781 [==============================] - 47s 61ms/step - loss: 0.5231 - accuracy: 0.8237 - val_loss: 0.4201 - val_accuracy: 0.8591\n",
      "Epoch 66/200\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.5297 - accuracy: 0.8211 - val_loss: 0.4316 - val_accuracy: 0.8534\n",
      "Epoch 67/200\n",
      "781/781 [==============================] - 46s 59ms/step - loss: 0.5277 - accuracy: 0.8210 - val_loss: 0.4568 - val_accuracy: 0.8498\n",
      "Epoch 68/200\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5199 - accuracy: 0.8243 - val_loss: 0.4569 - val_accuracy: 0.8492\n",
      "Epoch 69/200\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.5186 - accuracy: 0.8238 - val_loss: 0.5721 - val_accuracy: 0.8157\n",
      "Epoch 70/200\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.5118 - accuracy: 0.8289 - val_loss: 0.4281 - val_accuracy: 0.8563\n",
      "Epoch 71/200\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.5175 - accuracy: 0.8241 - val_loss: 0.3878 - val_accuracy: 0.8713\n",
      "Epoch 72/200\n",
      "781/781 [==============================] - 59s 75ms/step - loss: 0.5123 - accuracy: 0.8278 - val_loss: 0.4435 - val_accuracy: 0.8519\n",
      "Epoch 73/200\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.5083 - accuracy: 0.8276 - val_loss: 0.4240 - val_accuracy: 0.8559\n",
      "Epoch 74/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5069 - accuracy: 0.8297 - val_loss: 0.4715 - val_accuracy: 0.8463\n",
      "Epoch 75/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5161 - accuracy: 0.8235 - val_loss: 0.4436 - val_accuracy: 0.8572\n",
      "Epoch 76/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5051 - accuracy: 0.8294 - val_loss: 0.4461 - val_accuracy: 0.8492\n",
      "Epoch 77/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4994 - accuracy: 0.8331 - val_loss: 0.4372 - val_accuracy: 0.8552\n",
      "Epoch 78/200\n",
      "781/781 [==============================] - 1424s 2s/step - loss: 0.5121 - accuracy: 0.8269 - val_loss: 0.4214 - val_accuracy: 0.8629\n",
      "Epoch 79/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.5038 - accuracy: 0.8291 - val_loss: 0.4420 - val_accuracy: 0.8555\n",
      "Epoch 80/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.4986 - accuracy: 0.8356 - val_loss: 0.4399 - val_accuracy: 0.8543\n",
      "Epoch 81/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.4961 - accuracy: 0.8307 - val_loss: 0.4338 - val_accuracy: 0.8573\n",
      "Epoch 82/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.5004 - accuracy: 0.8312 - val_loss: 0.4544 - val_accuracy: 0.8464\n",
      "Epoch 83/200\n",
      "781/781 [==============================] - 36s 45ms/step - loss: 0.4954 - accuracy: 0.8334 - val_loss: 0.4397 - val_accuracy: 0.8584\n",
      "Epoch 84/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.4874 - accuracy: 0.8365 - val_loss: 0.4061 - val_accuracy: 0.8644\n",
      "Epoch 85/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.4988 - accuracy: 0.8304 - val_loss: 0.3995 - val_accuracy: 0.8661\n",
      "Epoch 86/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4911 - accuracy: 0.8332 - val_loss: 0.4350 - val_accuracy: 0.8547\n",
      "Epoch 87/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4939 - accuracy: 0.8351 - val_loss: 0.4242 - val_accuracy: 0.8589\n",
      "Epoch 88/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4903 - accuracy: 0.8345 - val_loss: 0.4213 - val_accuracy: 0.8611\n",
      "Epoch 89/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4895 - accuracy: 0.8354 - val_loss: 0.4203 - val_accuracy: 0.8607\n",
      "Epoch 90/200\n",
      "781/781 [==============================] - 32s 42ms/step - loss: 0.4834 - accuracy: 0.8364 - val_loss: 0.4251 - val_accuracy: 0.8600\n",
      "Epoch 91/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.4865 - accuracy: 0.8384 - val_loss: 0.4265 - val_accuracy: 0.8580\n",
      "Epoch 92/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.4943 - accuracy: 0.8324 - val_loss: 0.4444 - val_accuracy: 0.8565\n",
      "Epoch 93/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.4726 - accuracy: 0.8380 - val_loss: 0.4075 - val_accuracy: 0.8648\n",
      "Epoch 94/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4795 - accuracy: 0.8393 - val_loss: 0.4204 - val_accuracy: 0.8566\n",
      "Epoch 95/200\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.4856 - accuracy: 0.8349 - val_loss: 0.4808 - val_accuracy: 0.8441\n",
      "Epoch 96/200\n",
      "781/781 [==============================] - 32s 42ms/step - loss: 0.4727 - accuracy: 0.8429 - val_loss: 0.4018 - val_accuracy: 0.8671\n",
      "Epoch 97/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.4796 - accuracy: 0.8383 - val_loss: 0.4370 - val_accuracy: 0.8582\n",
      "Epoch 98/200\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.4644 - accuracy: 0.8461 - val_loss: 0.3941 - val_accuracy: 0.8671\n",
      "Epoch 99/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.4700 - accuracy: 0.8404 - val_loss: 0.3825 - val_accuracy: 0.8717\n",
      "Epoch 100/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.4778 - accuracy: 0.8384 - val_loss: 0.4567 - val_accuracy: 0.8511\n",
      "Epoch 101/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.4758 - accuracy: 0.8408 - val_loss: 0.4593 - val_accuracy: 0.8518\n",
      "Epoch 102/200\n",
      "781/781 [==============================] - 35s 44ms/step - loss: 0.4754 - accuracy: 0.8417 - val_loss: 0.4039 - val_accuracy: 0.8659\n",
      "Epoch 103/200\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4640 - accuracy: 0.8408 - val_loss: 0.4155 - val_accuracy: 0.8642\n",
      "Epoch 104/200\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.4636 - accuracy: 0.8436 - val_loss: 0.3884 - val_accuracy: 0.8688\n",
      "Epoch 105/200\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4699 - accuracy: 0.8419 - val_loss: 0.4382 - val_accuracy: 0.8567\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4653 - accuracy: 0.8445 - val_loss: 0.3825 - val_accuracy: 0.8696\n",
      "Epoch 107/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.4673 - accuracy: 0.8425 - val_loss: 0.4620 - val_accuracy: 0.8484\n",
      "Epoch 108/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.4643 - accuracy: 0.8432 - val_loss: 0.3886 - val_accuracy: 0.8743\n",
      "Epoch 109/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4598 - accuracy: 0.8456 - val_loss: 0.4196 - val_accuracy: 0.8634\n",
      "Epoch 110/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.4639 - accuracy: 0.8441 - val_loss: 0.4347 - val_accuracy: 0.8591\n",
      "Epoch 111/200\n",
      " 75/781 [=>............................] - ETA: 29s - loss: 0.4279 - accuracy: 0.8579"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m it_train \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow(x_train,y_train_cat)\n\u001b[0;32m     30\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test_cat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:2913\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2901\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2902\u001b[0m \n\u001b[0;32m   2903\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2904\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2905\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2906\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2907\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2908\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2909\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2910\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2911\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2912\u001b[0m )\n\u001b[1;32m-> 2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2915\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2925\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2927\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2928\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True,rotation_range=20)\n",
    "it_train = datagen.flow(x_train,y_train_cat)\n",
    "steps = int(x_train.shape[0] / 64)\n",
    "history=model.fit_generator(it_train,epochs=200,steps_per_epoch=steps,validation_data=(x_test,y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff16822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
